{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f90d45b",
   "metadata": {},
   "source": [
    "## Mixup : Beyond Empirical Risk Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a1a084",
   "metadata": {},
   "source": [
    "일반적으로 Large deep nerual networks는 굉장히 강력하지만 가지고 있는 데이터를 memoirization하는 경향이 있다.\n",
    "바꿔말하면 새로운 데이터에 둔감하여 오버피팅(Overfitting)의 위험은 커진다. Large deep nerual networks의 이러한 단점을 극복하기 위한 Data Augmentation의 기법, Mixup을 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec898661",
   "metadata": {},
   "source": [
    "### ERM(Empirical Risk Minimization)\n",
    "\n",
    "우리는 Risk(Loss)를 Minimization하는 모델을 구축하는 것을 목표로 한다. 하지만, 그것은 우리가 사용하는 훈련 데이터의 분포를 알고있다는 가정 하에서 이루어진다. 즉, 우리의 경험, 즉 우리의 데이터에 의해 이루어진다.\n",
    "\n",
    "때문에 ERM 기반의 nerual networks는 OOD(Out Of Distribution)에 약하다. 강한 규제(Regulation) 방법을 사용하더라도 새로운 데이터가 들어오면 어느정도 오버피팅(Overfitting)된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff1557a",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/74411831/126467499-1ed56479-6301-4506-a3e9-ff430c23ad8f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe518c",
   "metadata": {},
   "source": [
    "우리에게 주어진 데이터로 모델을 조금만 학습시키면, 성능(신뢰성, confidence)은 매우 낮을 것이고 그만큼 Risk(Loss)는 높을 것이다. 반대로 주어진 데이터로 모델을 오래 학습시키면, 모델이 데이터에 완전히 적합될 것이고 높은 성능을 보이겠지만 과도하게 데이터에 적합되어 오버피팅(Overfitting)이 발생할 것이다. 일반적인 ERM 모형에서는 위 그림에서 빨간점을 찾아야 한다는 점이 단점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92041042",
   "metadata": {},
   "source": [
    "### VRM(Vicinal Risk Minimization)\n",
    "\n",
    "VRM은 ERM의 단점을 해소하기 위해 훈련 데이터셋 뿐 아니라 훈련 데이터셋의 근방(Vicinal)분포도 활용한다는 특징이 있다. 훈련 데이터가 우리에게 주어진 데이터는 아니지만, 훈련 데이터와 크게 다르지 않은(Vicinal) 즉, Data Augmentation을 통해 VRM 기반 학습이 가능해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1025abb5",
   "metadata": {},
   "source": [
    "### Mix-up Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1a677",
   "metadata": {},
   "source": [
    "![classical_mixup](https://user-images.githubusercontent.com/74411831/126579250-44b9639c-73ad-48a4-b5c2-0c3c1f873cf6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1af3c",
   "metadata": {},
   "source": [
    "Mix-up data augmentation은 기존의 데이터와 Label을 Mix하여 새로운 데이터, Label을 만들어내는 데이터 증강 방법이다. 우리의 호흡음 데이터에 빗대어 본다면 Wheezing과 Healthy의 두 Audio Data에서 Extract한 Vector를 Mix하여 새로운 데이터 및 Label을 생성하여 근방분포(Vicinal)를 고려하는 VRM기반 학습을 가능하게 한다. 이 Mix-up Data Augmentation은 과적합을 막는 일종의 regularization의 역할을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266ec30",
   "metadata": {},
   "source": [
    "![hi](https://user-images.githubusercontent.com/74411831/126579673-31c9d990-08f3-4fb1-8127-d562e50a7737.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef986c6",
   "metadata": {},
   "source": [
    "Mix-up은 베타분포를 활용하여 Data Augmentation을 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
